\begin{center}
    \Large{\textbf{Аннотация}}
\end{center}

    В данной работе рассматривается проблема федеративного обучения. В подобных задачах зачастую требуется передавать большие объемы данных между устройствами, что может привести к узким местам в коммуникации. Для решения этой проблемы применяются операторы сжатия, которые позволяют уменьшить объем передаваемых данных. Однако, существующие методы сжатия не учитывают важность отдельных координат в процессе оптимизации, что может негативно сказаться на скорости сходимости алгоритмов. Для решения этой проблемы в работе вводится новое семейство операторов сжатия $\impk$, основанное на механизме важности, и исследуются их свойства. Также предлагается новый механизм компенсации ошибок SCAM, который значительно улучшает скорости сходимости как для новых операторов сжатия, так и для существующих смещенных компрессоров. Проведенные эксперименты на различных архитектурах подтверждают эффективность предложенных методов и их превосходство над существующими решениями в области распределенной оптимизации.